{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e051402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "train_in = pd.read_csv('train_in.csv', header=None)\n",
    "train_out = pd.read_csv('train_out.csv', header=None)\n",
    "test_in = pd.read_csv('test_in.csv', header=None)\n",
    "test_out = pd.read_csv('test_out.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a021eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert a column of one in the train set for the bias\n",
    "train_in.insert(0, 'w0', 1)\n",
    "test_in.insert(0, 'w0', 1)\n",
    "\n",
    "# -> need to generate Weights randomly\n",
    "# torch.randn(n_inp, n_out)*math.sqrt(2/n_inp)\n",
    "W = np.full((257, 10), 0.40)\n",
    "delta_w = np.full((257, 10), 0.00)\n",
    "\n",
    "# encode the desired label to binary colomns\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "trainout = pd.DataFrame(encoder.fit_transform(train_out).toarray())\n",
    "testout = pd.DataFrame(encoder.fit_transform(test_out).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bab7c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network on train set\n",
    "# -> set a better converge conditon\n",
    "for i in range(20):\n",
    "    for index, x in train_in.iterrows():\n",
    "        net = np.dot(x, W)           # linear regression\n",
    "        out = 1 / (1 + np.exp(-net)) # logistic regression\n",
    "        # generate the delta w using neuron learning rule\n",
    "        for i in range(trainout.shape[1]): \n",
    "            w_tran = 0.5 * x * (trainout.iloc[index].iloc[i] - out[i]) * out[i] * (1 - out[i])\n",
    "            w_tran = w_tran.values\n",
    "            w_tran = w_tran.reshape(1,-1).T\n",
    "            delta_w[:, i] = w_tran[:, 0]\n",
    "        W += delta_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c819339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.0896309314587\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy\n",
    "traincorrect = 0\n",
    "for i, x in train_in.iterrows():\n",
    "    pre = np.full((1, 9), 0.00)\n",
    "    phi = 1 / (1 + np.exp(-np.dot(x, W)))\n",
    "    digit = np.argmax(phi)\n",
    "    output = np.insert(pre, digit, 1)\n",
    "    if np.array_equiv(trainout.values[i], output):\n",
    "        traincorrect += 1\n",
    "correctr_train = traincorrect / len(train_in) * 100\n",
    "print(correctr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ab6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c231219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
